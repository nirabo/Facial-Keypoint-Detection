{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# 01 - Data Exploration\n",
    "\n",
    "This notebook demonstrates how to load and explore the Kaggle Facial Keypoints Detection dataset.\n",
    "\n",
    "## Overview\n",
    "\n",
    "- Load training data from CSV files\n",
    "- Explore data statistics and distributions\n",
    "- Visualize sample images with keypoints\n",
    "- Understand the data format and preprocessing\n",
    "\n",
    "## Dataset Info\n",
    "\n",
    "- **Source**: [Kaggle Facial Keypoints Detection](https://www.kaggle.com/c/facial-keypoints-detection)\n",
    "- **Images**: 96x96 grayscale\n",
    "- **Keypoints**: 15 facial landmarks (30 values: x,y pairs)\n",
    "- **Training samples**: ~7000 (but only ~2140 have all 15 keypoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Package imports\n",
    "from facial_keypoints.data.loader import load_data, get_data_statistics\n",
    "from facial_keypoints.data.download import get_data_info, verify_data\n",
    "from facial_keypoints.visualization.plotting import plot_keypoints, plot_training_samples\n",
    "\n",
    "# Display settings\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (12, 12)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-2",
   "metadata": {},
   "source": [
    "## 1. Verify Data Availability\n",
    "\n",
    "First, let's check if the data files are present and get basic info about them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check data status\n",
    "status = verify_data()\n",
    "print(\"Data file status:\")\n",
    "for filename, valid in status.items():\n",
    "    symbol = \"OK\" if valid else \"MISSING\"\n",
    "    print(f\"  {filename}: {symbol}\")\n",
    "\n",
    "if not all(status.values()):\n",
    "    print(\"\\nData files missing! Run: python scripts/download_data.py --kaggle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get detailed data info\n",
    "info = get_data_info()\n",
    "print(\"Dataset Information\")\n",
    "print(\"=\" * 40)\n",
    "for key, value in info.items():\n",
    "    print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-5",
   "metadata": {},
   "source": [
    "## 2. Explore Raw CSV Data\n",
    "\n",
    "Let's look at the raw CSV structure before loading through our preprocessing pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load raw CSV to explore structure\n",
    "df_raw = pd.read_csv(\"../data/training.csv\")\n",
    "\n",
    "print(f\"Raw dataframe shape: {df_raw.shape}\")\n",
    "print(f\"\\nColumns ({len(df_raw.columns)}):\")\n",
    "for i, col in enumerate(df_raw.columns):\n",
    "    print(f\"  {i:2d}. {col}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values in each keypoint column\n",
    "keypoint_cols = [c for c in df_raw.columns if c != 'Image']\n",
    "missing_counts = df_raw[keypoint_cols].isnull().sum()\n",
    "\n",
    "print(\"Missing values per keypoint:\")\n",
    "print(\"=\" * 50)\n",
    "for col, count in missing_counts.items():\n",
    "    pct = count / len(df_raw) * 100\n",
    "    bar = \"#\" * int(pct / 2)\n",
    "    print(f\"{col:30s}: {count:4d} ({pct:5.1f}%) {bar}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Samples with ALL keypoints vs partial\n",
    "complete_mask = df_raw[keypoint_cols].notnull().all(axis=1)\n",
    "n_complete = complete_mask.sum()\n",
    "n_partial = len(df_raw) - n_complete\n",
    "\n",
    "print(f\"Samples with ALL 15 keypoints: {n_complete} ({n_complete/len(df_raw)*100:.1f}%)\")\n",
    "print(f\"Samples with partial keypoints: {n_partial} ({n_partial/len(df_raw)*100:.1f}%)\")\n",
    "\n",
    "# Visualize\n",
    "fig, ax = plt.subplots(figsize=(8, 5))\n",
    "ax.bar(['Complete (all 15)', 'Partial'], [n_complete, n_partial], color=['steelblue', 'lightcoral'])\n",
    "ax.set_ylabel('Number of Samples')\n",
    "ax.set_title('Dataset Completeness')\n",
    "for i, v in enumerate([n_complete, n_partial]):\n",
    "    ax.text(i, v + 50, str(v), ha='center', fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-9",
   "metadata": {},
   "source": [
    "## 3. Load Preprocessed Training Data\n",
    "\n",
    "The `load_data()` function:\n",
    "- Drops rows with missing keypoints (only keeps complete samples)\n",
    "- Normalizes images to [0, 1]\n",
    "- Normalizes keypoints to [-1, 1]\n",
    "- Reshapes images to (N, 96, 96, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load preprocessed training data\n",
    "X_train, y_train = load_data(test=False)\n",
    "\n",
    "print(f\"Training images shape: {X_train.shape}\")\n",
    "print(f\"Training keypoints shape: {y_train.shape}\")\n",
    "print(f\"\\nImage dtype: {X_train.dtype}\")\n",
    "print(f\"Keypoints dtype: {y_train.dtype}\")\n",
    "print(f\"\\nImage value range: [{X_train.min():.4f}, {X_train.max():.4f}]\")\n",
    "print(f\"Keypoint value range: [{y_train.min():.4f}, {y_train.max():.4f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-11",
   "metadata": {},
   "source": [
    "## 4. Data Statistics\n",
    "\n",
    "Use `get_data_statistics()` to compute summary statistics for validation and exploration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute statistics\n",
    "stats = get_data_statistics(X_train, y_train)\n",
    "\n",
    "print(\"Dataset Statistics\")\n",
    "print(\"=\" * 40)\n",
    "print(f\"Number of samples: {stats['n_samples']}\")\n",
    "print(f\"Image dimensions: {stats['image_height']}x{stats['image_width']}\")\n",
    "print(f\"Number of keypoints: {stats['n_keypoints']}\")\n",
    "print()\n",
    "print(\"Image Value Statistics (normalized [0, 1])\")\n",
    "print(f\"  Min: {stats['x_min']:.4f}\")\n",
    "print(f\"  Max: {stats['x_max']:.4f}\")\n",
    "print(f\"  Mean: {stats['x_mean']:.4f}\")\n",
    "print(f\"  Std: {stats['x_std']:.4f}\")\n",
    "print()\n",
    "print(\"Keypoint Statistics (normalized [-1, 1])\")\n",
    "print(f\"  Min: {stats['y_min']:.4f}\")\n",
    "print(f\"  Max: {stats['y_max']:.4f}\")\n",
    "print(f\"  Mean: {stats['y_mean']:.4f}\")\n",
    "print(f\"  Std: {stats['y_std']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-13",
   "metadata": {},
   "source": [
    "## 5. Visualize Training Samples\n",
    "\n",
    "The `plot_training_samples()` function displays a grid of images with their keypoints overlaid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a grid of training samples\n",
    "fig = plot_training_samples(X_train, y_train, n_samples=16, figsize=(14, 14))\n",
    "plt.suptitle(\"Training Samples with 15 Facial Keypoints\", fontsize=14, y=1.02)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-15",
   "metadata": {},
   "source": [
    "## 6. Individual Sample Visualization\n",
    "\n",
    "Use `plot_keypoints()` for detailed visualization of a single sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize a single sample with different marker styles\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "# Sample index to visualize\n",
    "idx = 42\n",
    "\n",
    "# Original image without keypoints\n",
    "axes[0].imshow(X_train[idx].squeeze(), cmap='gray')\n",
    "axes[0].set_title('Original Image')\n",
    "axes[0].axis('off')\n",
    "\n",
    "# With cyan keypoints (default)\n",
    "plot_keypoints(X_train[idx], y_train[idx], ax=axes[1], \n",
    "               denormalize=True, marker_color='cyan', marker_size=40)\n",
    "axes[1].set_title('Cyan Keypoints')\n",
    "\n",
    "# With red keypoints\n",
    "plot_keypoints(X_train[idx], y_train[idx], ax=axes[2],\n",
    "               denormalize=True, marker_color='red', marker_size=60)\n",
    "axes[2].set_title('Red Keypoints (larger)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-17",
   "metadata": {},
   "source": [
    "## 7. Keypoint Distribution Analysis\n",
    "\n",
    "Analyze the distribution of keypoint positions across the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keypoint names for reference\n",
    "KEYPOINT_NAMES = [\n",
    "    'left_eye_center',\n",
    "    'right_eye_center', \n",
    "    'left_eye_inner_corner',\n",
    "    'left_eye_outer_corner',\n",
    "    'right_eye_inner_corner',\n",
    "    'right_eye_outer_corner',\n",
    "    'left_eyebrow_inner',\n",
    "    'left_eyebrow_outer',\n",
    "    'right_eyebrow_inner',\n",
    "    'right_eyebrow_outer',\n",
    "    'nose_tip',\n",
    "    'mouth_left_corner',\n",
    "    'mouth_right_corner',\n",
    "    'mouth_center_top',\n",
    "    'mouth_center_bottom'\n",
    "]\n",
    "\n",
    "print(\"Keypoint Index Legend:\")\n",
    "for i, name in enumerate(KEYPOINT_NAMES):\n",
    "    print(f\"  {i:2d}: {name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Denormalize keypoints to pixel coordinates for analysis\n",
    "y_pixels = y_train * 48 + 48\n",
    "\n",
    "# Reshape to (n_samples, n_keypoints, 2)\n",
    "y_reshaped = y_pixels.reshape(-1, 15, 2)\n",
    "\n",
    "# Compute mean and std position for each keypoint\n",
    "mean_positions = y_reshaped.mean(axis=0)\n",
    "std_positions = y_reshaped.std(axis=0)\n",
    "\n",
    "print(\"Mean keypoint positions (pixel coords):\")\n",
    "for i, (name, pos, std) in enumerate(zip(KEYPOINT_NAMES, mean_positions, std_positions)):\n",
    "    print(f\"  {i:2d}. {name:25s}: ({pos[0]:5.1f}, {pos[1]:5.1f}) +/- ({std[0]:4.1f}, {std[1]:4.1f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot mean keypoint positions on a reference grid\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "ax.set_xlim(0, 96)\n",
    "ax.set_ylim(96, 0)  # Invert y-axis (image coordinates)\n",
    "ax.set_aspect('equal')\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot mean positions with error ellipses\n",
    "colors = plt.cm.tab20(np.linspace(0, 1, 15))\n",
    "for i, (pos, std, color) in enumerate(zip(mean_positions, std_positions, colors)):\n",
    "    ax.scatter(pos[0], pos[1], s=150, c=[color], marker='o', edgecolors='black', zorder=10)\n",
    "    ax.annotate(str(i), (pos[0], pos[1]), xytext=(5, 5), textcoords='offset points', \n",
    "                fontsize=10, fontweight='bold')\n",
    "\n",
    "ax.set_title('Mean Keypoint Positions (96x96 image space)', fontsize=14)\n",
    "ax.set_xlabel('X coordinate (pixels)')\n",
    "ax.set_ylabel('Y coordinate (pixels)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-21",
   "metadata": {},
   "source": [
    "## 8. Pixel Intensity Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot pixel intensity histogram\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Overall pixel distribution\n",
    "axes[0].hist(X_train.flatten(), bins=50, color='steelblue', edgecolor='black', alpha=0.7)\n",
    "axes[0].set_xlabel('Pixel Value (normalized 0-1)')\n",
    "axes[0].set_ylabel('Frequency')\n",
    "axes[0].set_title('Pixel Intensity Distribution')\n",
    "axes[0].axvline(X_train.mean(), color='red', linestyle='--', linewidth=2,\n",
    "                label=f'Mean: {X_train.mean():.3f}')\n",
    "axes[0].legend()\n",
    "\n",
    "# Keypoint coordinate distribution\n",
    "axes[1].hist(y_train.flatten(), bins=50, color='coral', edgecolor='black', alpha=0.7)\n",
    "axes[1].set_xlabel('Keypoint Coordinate (normalized -1 to 1)')\n",
    "axes[1].set_ylabel('Frequency')\n",
    "axes[1].set_title('Keypoint Coordinate Distribution')\n",
    "axes[1].axvline(y_train.mean(), color='red', linestyle='--', linewidth=2,\n",
    "                label=f'Mean: {y_train.mean():.3f}')\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-23",
   "metadata": {},
   "source": [
    "## 9. Per-Keypoint Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Box plot for each keypoint's X and Y coordinates\n",
    "fig, axes = plt.subplots(2, 1, figsize=(16, 10))\n",
    "\n",
    "# X coordinates (even indices)\n",
    "x_coords = y_pixels[:, 0::2]  # Shape: (n_samples, 15)\n",
    "y_coords = y_pixels[:, 1::2]  # Shape: (n_samples, 15)\n",
    "\n",
    "# X coordinate boxplot\n",
    "bp1 = axes[0].boxplot(x_coords, labels=range(15), patch_artist=True)\n",
    "for patch in bp1['boxes']:\n",
    "    patch.set_facecolor('lightblue')\n",
    "axes[0].set_ylabel('X coordinate (pixels)')\n",
    "axes[0].set_xlabel('Keypoint Index')\n",
    "axes[0].set_title('X Coordinate Distribution per Keypoint')\n",
    "axes[0].axhline(48, color='red', linestyle='--', alpha=0.5, label='Image center')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Y coordinate boxplot\n",
    "bp2 = axes[1].boxplot(y_coords, labels=range(15), patch_artist=True)\n",
    "for patch in bp2['boxes']:\n",
    "    patch.set_facecolor('lightcoral')\n",
    "axes[1].set_ylabel('Y coordinate (pixels)')\n",
    "axes[1].set_xlabel('Keypoint Index')\n",
    "axes[1].set_title('Y Coordinate Distribution per Keypoint')\n",
    "axes[1].axhline(48, color='red', linestyle='--', alpha=0.5, label='Image center')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-25",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrated:\n",
    "\n",
    "1. **Data Verification**: Using `verify_data()` and `get_data_info()` to check data availability\n",
    "2. **Raw Data Exploration**: Understanding the CSV structure and missing value patterns\n",
    "3. **Preprocessed Loading**: Using `load_data()` to get normalized images and keypoints\n",
    "4. **Statistics**: Using `get_data_statistics()` for dataset validation\n",
    "5. **Visualization**: Using `plot_keypoints()` and `plot_training_samples()` for visual inspection\n",
    "6. **Distribution Analysis**: Understanding keypoint distributions and image properties\n",
    "\n",
    "### Key Findings\n",
    "\n",
    "- The dataset has ~7000 total samples, but only ~2140 have all 15 keypoints\n",
    "- Many samples have partial annotations (eyes only, or missing some features)\n",
    "- The current loader drops partial samples for training consistency\n",
    "- Keypoints are roughly centered in the images with moderate variance\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "- Proceed to `02_model_training.ipynb` to train a CNN model\n",
    "- Or jump to `03_inference_pipeline.ipynb` to use a pre-trained model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
