{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 03 - Inference Pipeline\n",
    "\n",
    "This notebook demonstrates the end-to-end facial keypoint detection pipeline using the modernized `facial_keypoints` package.\n",
    "\n",
    "## Overview\n",
    "\n",
    "- Use `FacialKeypointsPipeline` for complete face detection + keypoint prediction\n",
    "- Process images with multiple faces\n",
    "- Visualize results with bounding boxes and keypoints\n",
    "- Explore individual pipeline components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard imports\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "# Package imports\n",
    "from facial_keypoints.pipeline import FacialKeypointsPipeline, PipelineResult\n",
    "from facial_keypoints.detection.face_detector import FaceDetector, BoundingBox\n",
    "from facial_keypoints.models.predictor import KeypointPredictor\n",
    "from facial_keypoints.visualization.plotting import (\n",
    "    plot_keypoints,\n",
    "    plot_face_detections,\n",
    "    plot_pipeline_result,\n",
    ")\n",
    "\n",
    "# Display settings\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (12, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Initialize the Pipeline\n",
    "\n",
    "The `FacialKeypointsPipeline` combines face detection (Haar Cascades) with keypoint prediction (CNN)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the pipeline\n",
    "# Note: Requires cascade file and trained model\n",
    "try:\n",
    "    pipeline = FacialKeypointsPipeline(\n",
    "        cascade_path=\"detector_architectures/haarcascade_frontalface_default.xml\",\n",
    "        model_path=\"models/keypoint_model.keras\",  # Or your trained model path\n",
    "    )\n",
    "    print(\"✓ Pipeline initialized successfully!\")\n",
    "    print(f\"  Cascade: {pipeline.face_detector.cascade_path}\")\n",
    "    print(f\"  Model: {pipeline.keypoint_predictor.model_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"Could not initialize pipeline: {e}\")\n",
    "    print(\"\\nMake sure you have:\")\n",
    "    print(\"  1. Haar cascade file in detector_architectures/\")\n",
    "    print(\"  2. Trained model in models/ (run notebook 02 first)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Process a Single Image\n",
    "\n",
    "Use `pipeline.process()` to detect faces and predict keypoints in one call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process an image\n",
    "try:\n",
    "    # Load a test image (update path as needed)\n",
    "    image_path = \"images/james.jpg\"  # Example image from the project\n",
    "    \n",
    "    if not Path(image_path).exists():\n",
    "        print(f\"Image not found: {image_path}\")\n",
    "        print(\"Update the path to an existing image file.\")\n",
    "    else:\n",
    "        result = pipeline.process(image_path)\n",
    "        \n",
    "        print(f\"Processed image: {image_path}\")\n",
    "        print(f\"Image shape: {result.image.shape}\")\n",
    "        print(f\"Faces detected: {result.n_faces}\")\n",
    "        \n",
    "        for i, face in enumerate(result.faces):\n",
    "            box = face.bounding_box\n",
    "            print(f\"\\nFace {i + 1}:\")\n",
    "            print(f\"  Bounding box: ({box.x}, {box.y}, {box.width}×{box.height})\")\n",
    "            print(f\"  Center: {box.center}\")\n",
    "            print(f\"  Keypoints shape: {face.keypoints.shape}\")\n",
    "except NameError:\n",
    "    print(\"Pipeline not initialized - run the cell above first\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Visualize Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the pipeline results\n",
    "try:\n",
    "    fig = plot_pipeline_result(\n",
    "        result.image,\n",
    "        result.faces,\n",
    "        figsize=(12, 12),\n",
    "        show_boxes=True,\n",
    "        show_keypoints=True,\n",
    "        keypoint_color='cyan',\n",
    "        keypoint_size=50,\n",
    "    )\n",
    "    plt.show()\n",
    "except NameError:\n",
    "    print(\"No results to visualize - run the processing cell first\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Process Multiple Images\n",
    "\n",
    "Batch process multiple images from a directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_directory(pipeline, image_dir, extensions=('.jpg', '.jpeg', '.png')):\n",
    "    \"\"\"Process all images in a directory.\"\"\"\n",
    "    image_dir = Path(image_dir)\n",
    "    results = []\n",
    "    \n",
    "    for ext in extensions:\n",
    "        for image_path in image_dir.glob(f'*{ext}'):\n",
    "            try:\n",
    "                result = pipeline.process(str(image_path))\n",
    "                results.append((image_path.name, result))\n",
    "                print(f\"✓ {image_path.name}: {result.n_faces} face(s)\")\n",
    "            except Exception as e:\n",
    "                print(f\"✗ {image_path.name}: {e}\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Process all images in the images/ directory\n",
    "try:\n",
    "    if Path('images').exists():\n",
    "        all_results = process_directory(pipeline, 'images')\n",
    "        print(f\"\\nProcessed {len(all_results)} images\")\n",
    "    else:\n",
    "        print(\"images/ directory not found\")\n",
    "except NameError:\n",
    "    print(\"Pipeline not initialized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Compare Detection Methods\n",
    "\n",
    "Show different ways to process faces: detect all vs. detect single largest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare detect_all=True vs detect_all=False\n",
    "try:\n",
    "    image_path = \"images/obamas.jpg\"  # An image with multiple faces\n",
    "    \n",
    "    if Path(image_path).exists():\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(16, 8))\n",
    "        \n",
    "        # Detect all faces\n",
    "        result_all = pipeline.process(image_path, detect_all=True)\n",
    "        img_rgb = cv2.cvtColor(result_all.image.copy(), cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # Draw all faces\n",
    "        for face in result_all.faces:\n",
    "            box = face.bounding_box\n",
    "            cv2.rectangle(img_rgb, (box.x, box.y), \n",
    "                          (box.x + box.width, box.y + box.height), (0, 255, 0), 3)\n",
    "        axes[0].imshow(img_rgb)\n",
    "        axes[0].set_title(f'detect_all=True ({result_all.n_faces} faces)')\n",
    "        axes[0].axis('off')\n",
    "        \n",
    "        # Detect single (largest) face\n",
    "        result_single = pipeline.process(image_path, detect_all=False)\n",
    "        img_rgb2 = cv2.cvtColor(result_single.image.copy(), cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        for face in result_single.faces:\n",
    "            box = face.bounding_box\n",
    "            cv2.rectangle(img_rgb2, (box.x, box.y),\n",
    "                          (box.x + box.width, box.y + box.height), (255, 0, 0), 3)\n",
    "        axes[1].imshow(img_rgb2)\n",
    "        axes[1].set_title(f'detect_all=False (largest face only)')\n",
    "        axes[1].axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(f\"Multi-face image not found: {image_path}\")\n",
    "except NameError:\n",
    "    print(\"Pipeline not initialized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Using Individual Components\n",
    "\n",
    "You can also use `FaceDetector` and `KeypointPredictor` separately for more control."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use FaceDetector independently\n",
    "try:\n",
    "    detector = FaceDetector(\n",
    "        cascade_path=\"detector_architectures/haarcascade_frontalface_default.xml\",\n",
    "        scale_factor=1.2,\n",
    "        min_neighbors=5,\n",
    "    )\n",
    "    \n",
    "    image = cv2.imread(\"images/james.jpg\")\n",
    "    if image is not None:\n",
    "        boxes = detector.detect(image)\n",
    "        \n",
    "        print(f\"Detected {len(boxes)} faces:\")\n",
    "        for i, box in enumerate(boxes):\n",
    "            print(f\"  Face {i + 1}: x={box.x}, y={box.y}, \"\n",
    "                  f\"size={box.width}×{box.height}, area={box.area}\")\n",
    "        \n",
    "        # Visualize\n",
    "        fig = plot_face_detections(image, boxes, title=\"Face Detection Results\")\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(\"Could not load image\")\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use KeypointPredictor independently\n",
    "try:\n",
    "    predictor = KeypointPredictor(\n",
    "        model_path=\"models/keypoint_model.keras\",\n",
    "        image_size=96,\n",
    "    )\n",
    "    \n",
    "    # Get a face crop\n",
    "    if len(boxes) > 0:\n",
    "        box = boxes[0]\n",
    "        face_crop = detector.crop_face(image, box, padding=0.1)\n",
    "        \n",
    "        # Predict keypoints\n",
    "        prediction = predictor.predict(face_crop, denormalize=True)\n",
    "        \n",
    "        print(f\"Raw output shape: {prediction.raw_output.shape}\")\n",
    "        print(f\"Keypoints shape: {prediction.keypoints.shape}\")\n",
    "        print(f\"\\nKeypoint coordinates (in 96×96 space):\")\n",
    "        for i, (x, y) in enumerate(prediction.keypoints):\n",
    "            print(f\"  Keypoint {i:2d}: ({x:6.2f}, {y:6.2f})\")\n",
    "        \n",
    "        # Visualize on crop\n",
    "        fig, ax = plt.subplots(figsize=(6, 6))\n",
    "        gray_crop = cv2.cvtColor(face_crop, cv2.COLOR_BGR2GRAY)\n",
    "        gray_resized = cv2.resize(gray_crop, (96, 96))\n",
    "        plot_keypoints(gray_resized, prediction.keypoints.flatten(), ax=ax)\n",
    "        ax.set_title('Keypoints on Face Crop')\n",
    "        plt.show()\n",
    "except NameError:\n",
    "    print(\"Detector or boxes not available\")\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Process from Webcam (Optional)\n",
    "\n",
    "Real-time keypoint detection using webcam input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def capture_and_process(pipeline, n_frames=1):\n",
    "    \"\"\"Capture frames from webcam and process them.\"\"\"\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    results = []\n",
    "    \n",
    "    try:\n",
    "        for i in range(n_frames):\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                print(\"Could not capture frame\")\n",
    "                break\n",
    "            \n",
    "            result = pipeline.process(frame)\n",
    "            results.append(result)\n",
    "            print(f\"Frame {i + 1}: {result.n_faces} face(s) detected\")\n",
    "    finally:\n",
    "        cap.release()\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Uncomment to capture from webcam\n",
    "# try:\n",
    "#     webcam_results = capture_and_process(pipeline, n_frames=1)\n",
    "#     if webcam_results:\n",
    "#         fig = plot_pipeline_result(webcam_results[0].image, webcam_results[0].faces)\n",
    "#         plt.show()\n",
    "# except Exception as e:\n",
    "#     print(f\"Webcam error: {e}\")\n",
    "\n",
    "print(\"Webcam capture disabled. Uncomment the code above to enable.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Export Results\n",
    "\n",
    "Save processed images or keypoint coordinates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_result(result, output_path, draw_boxes=True, draw_keypoints=True):\n",
    "    \"\"\"Save processed result to an image file.\"\"\"\n",
    "    img = result.image.copy()\n",
    "    \n",
    "    for face in result.faces:\n",
    "        box = face.bounding_box\n",
    "        \n",
    "        if draw_boxes:\n",
    "            cv2.rectangle(img, (box.x, box.y),\n",
    "                          (box.x + box.width, box.y + box.height), (0, 255, 0), 2)\n",
    "        \n",
    "        if draw_keypoints:\n",
    "            for x, y in face.keypoints:\n",
    "                cv2.circle(img, (int(x), int(y)), 3, (0, 255, 255), -1)\n",
    "    \n",
    "    cv2.imwrite(str(output_path), img)\n",
    "    print(f\"Saved: {output_path}\")\n",
    "\n",
    "# Save a processed result\n",
    "try:\n",
    "    output_dir = Path('output')\n",
    "    output_dir.mkdir(exist_ok=True)\n",
    "    \n",
    "    save_result(result, output_dir / 'processed_result.jpg')\n",
    "except NameError:\n",
    "    print(\"No result to save\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export keypoints to JSON\n",
    "import json\n",
    "\n",
    "def export_keypoints_json(result, output_path):\n",
    "    \"\"\"Export keypoints to JSON format.\"\"\"\n",
    "    data = {\n",
    "        \"n_faces\": result.n_faces,\n",
    "        \"faces\": []\n",
    "    }\n",
    "    \n",
    "    for i, face in enumerate(result.faces):\n",
    "        face_data = {\n",
    "            \"face_id\": i,\n",
    "            \"bounding_box\": {\n",
    "                \"x\": int(face.bounding_box.x),\n",
    "                \"y\": int(face.bounding_box.y),\n",
    "                \"width\": int(face.bounding_box.width),\n",
    "                \"height\": int(face.bounding_box.height),\n",
    "            },\n",
    "            \"keypoints\": [\n",
    "                {\"x\": float(x), \"y\": float(y)}\n",
    "                for x, y in face.keypoints\n",
    "            ]\n",
    "        }\n",
    "        data[\"faces\"].append(face_data)\n",
    "    \n",
    "    with open(output_path, 'w') as f:\n",
    "        json.dump(data, f, indent=2)\n",
    "    \n",
    "    print(f\"Exported keypoints to: {output_path}\")\n",
    "\n",
    "try:\n",
    "    export_keypoints_json(result, output_dir / 'keypoints.json')\n",
    "except NameError:\n",
    "    print(\"No result to export\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrated:\n",
    "\n",
    "1. **Pipeline Usage**: `FacialKeypointsPipeline` for end-to-end processing\n",
    "2. **Visualization**: `plot_pipeline_result()` and related functions\n",
    "3. **Component Access**: Using `FaceDetector` and `KeypointPredictor` independently\n",
    "4. **Batch Processing**: Processing multiple images from a directory\n",
    "5. **Export**: Saving results as images or JSON\n",
    "\n",
    "### API Reference\n",
    "\n",
    "```python\n",
    "# High-level pipeline\n",
    "from facial_keypoints.pipeline import FacialKeypointsPipeline\n",
    "pipeline = FacialKeypointsPipeline(cascade_path, model_path)\n",
    "result = pipeline.process(image)  # Returns PipelineResult\n",
    "\n",
    "# Low-level components\n",
    "from facial_keypoints.detection.face_detector import FaceDetector\n",
    "from facial_keypoints.models.predictor import KeypointPredictor\n",
    "\n",
    "detector = FaceDetector(cascade_path)\n",
    "boxes = detector.detect(image)  # Returns list[BoundingBox]\n",
    "\n",
    "predictor = KeypointPredictor(model_path)\n",
    "prediction = predictor.predict(face_crop)  # Returns KeypointPrediction\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
