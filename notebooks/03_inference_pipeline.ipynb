{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# 03 - Inference Pipeline\n",
    "\n",
    "This notebook demonstrates the end-to-end facial keypoint detection pipeline.\n",
    "\n",
    "## Overview\n",
    "\n",
    "- Use `FacialKeypointsPipeline` for complete face detection + keypoint prediction\n",
    "- Process images with multiple faces\n",
    "- Visualize results with bounding boxes and keypoints\n",
    "- Explore individual pipeline components\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "- Trained model from `02_model_training.ipynb` (saved in `models/`)\n",
    "- Haar cascade file in `detector_architectures/`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard imports\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "# Package imports\n",
    "from facial_keypoints.pipeline import FacialKeypointsPipeline\n",
    "from facial_keypoints.detection.face_detector import FaceDetector\n",
    "from facial_keypoints.models.predictor import KeypointPredictor\n",
    "from facial_keypoints.visualization.plotting import (\n",
    "    plot_keypoints,\n",
    "    plot_face_detections,\n",
    "    plot_pipeline_result,\n",
    ")\n",
    "\n",
    "# Display settings\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (12, 10)\n",
    "\n",
    "# Set paths relative to notebook location\n",
    "PROJECT_ROOT = Path('..').resolve()\n",
    "print(f\"Project root: {PROJECT_ROOT}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-2",
   "metadata": {},
   "source": [
    "## 1. Check Prerequisites\n",
    "\n",
    "Verify that required files exist before initializing the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for required files\n",
    "cascade_path = PROJECT_ROOT / 'detector_architectures' / 'haarcascade_frontalface_default.xml'\n",
    "model_path = PROJECT_ROOT / 'models' / 'model.keras'\n",
    "best_model_path = PROJECT_ROOT / 'models' / 'best_model.keras'\n",
    "images_dir = PROJECT_ROOT / 'images'\n",
    "\n",
    "print(\"File Availability Check\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Haar Cascade:  {'OK' if cascade_path.exists() else 'MISSING'} - {cascade_path}\")\n",
    "print(f\"Trained Model: {'OK' if model_path.exists() else 'MISSING'} - {model_path}\")\n",
    "print(f\"Best Model:    {'OK' if best_model_path.exists() else 'MISSING'} - {best_model_path}\")\n",
    "print(f\"Images Dir:    {'OK' if images_dir.exists() else 'MISSING'} - {images_dir}\")\n",
    "\n",
    "# Use best model if available, otherwise use model.keras\n",
    "if best_model_path.exists():\n",
    "    use_model_path = best_model_path\n",
    "elif model_path.exists():\n",
    "    use_model_path = model_path\n",
    "else:\n",
    "    use_model_path = None\n",
    "    print(\"\\nNo trained model found! Run 02_model_training.ipynb first.\")\n",
    "\n",
    "if use_model_path:\n",
    "    print(f\"\\nUsing model: {use_model_path.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-4",
   "metadata": {},
   "source": [
    "## 2. Initialize the Pipeline\n",
    "\n",
    "The `FacialKeypointsPipeline` combines face detection (Haar Cascades) with keypoint prediction (CNN)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the pipeline\n",
    "if use_model_path and cascade_path.exists():\n",
    "    pipeline = FacialKeypointsPipeline(\n",
    "        cascade_path=str(cascade_path),\n",
    "        model_path=str(use_model_path),\n",
    "    )\n",
    "    print(\"Pipeline initialized successfully!\")\n",
    "    print(f\"  Cascade: {cascade_path.name}\")\n",
    "    print(f\"  Model: {use_model_path.name}\")\n",
    "else:\n",
    "    pipeline = None\n",
    "    print(\"Cannot initialize pipeline - missing required files.\")\n",
    "    print(\"\\nTo continue:\")\n",
    "    print(\"  1. Ensure haarcascade file exists in detector_architectures/\")\n",
    "    print(\"  2. Train a model using 02_model_training.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-6",
   "metadata": {},
   "source": [
    "## 3. List Available Test Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List available images\n",
    "if images_dir.exists():\n",
    "    image_files = list(images_dir.glob('*.jpg')) + list(images_dir.glob('*.png'))\n",
    "    print(f\"Found {len(image_files)} images in {images_dir}:\")\n",
    "    for img_path in image_files:\n",
    "        size_kb = img_path.stat().st_size / 1024\n",
    "        print(f\"  - {img_path.name} ({size_kb:.1f} KB)\")\n",
    "else:\n",
    "    print(\"Images directory not found\")\n",
    "    image_files = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-8",
   "metadata": {},
   "source": [
    "## 4. Process a Single Image\n",
    "\n",
    "Use `pipeline.process()` to detect faces and predict keypoints in one call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process first available image\n",
    "if pipeline and image_files:\n",
    "    # Select first image\n",
    "    test_image_path = image_files[0]\n",
    "    print(f\"Processing: {test_image_path}\")\n",
    "    \n",
    "    # Process with pipeline\n",
    "    result = pipeline.process(str(test_image_path))\n",
    "    \n",
    "    print(f\"\\nResults:\")\n",
    "    print(f\"  Image shape: {result.image.shape}\")\n",
    "    print(f\"  Faces detected: {result.n_faces}\")\n",
    "    \n",
    "    for i, face in enumerate(result.faces):\n",
    "        box = face.bounding_box\n",
    "        print(f\"\\n  Face {i + 1}:\")\n",
    "        print(f\"    Bounding box: ({box.x}, {box.y}) size {box.width}x{box.height}\")\n",
    "        print(f\"    Center: {box.center}\")\n",
    "        print(f\"    Keypoints: {face.keypoints.shape[0]} points\")\n",
    "else:\n",
    "    result = None\n",
    "    print(\"Cannot process - pipeline not initialized or no images available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-10",
   "metadata": {},
   "source": [
    "## 5. Visualize Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the pipeline results\n",
    "if result:\n",
    "    fig = plot_pipeline_result(\n",
    "        result.image,\n",
    "        result.faces,\n",
    "        figsize=(12, 12),\n",
    "        show_boxes=True,\n",
    "        show_keypoints=True,\n",
    "        keypoint_color='cyan',\n",
    "        keypoint_size=50,\n",
    "    )\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No results to visualize\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-12",
   "metadata": {},
   "source": [
    "## 6. Process All Test Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process all available images\n",
    "if pipeline and image_files:\n",
    "    all_results = []\n",
    "    \n",
    "    print(\"Processing all images...\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    for img_path in image_files:\n",
    "        try:\n",
    "            res = pipeline.process(str(img_path))\n",
    "            all_results.append((img_path.name, res))\n",
    "            status = \"OK\"\n",
    "            n_faces = res.n_faces\n",
    "        except Exception as e:\n",
    "            status = f\"ERROR: {e}\"\n",
    "            n_faces = 0\n",
    "        \n",
    "        print(f\"{img_path.name:30s} - {n_faces} face(s) - {status}\")\n",
    "    \n",
    "    print(f\"\\nProcessed {len(all_results)} images\")\n",
    "    total_faces = sum(r.n_faces for _, r in all_results)\n",
    "    print(f\"Total faces detected: {total_faces}\")\n",
    "else:\n",
    "    all_results = []\n",
    "    print(\"Cannot process images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display all results in a grid\n",
    "if all_results:\n",
    "    n_images = len(all_results)\n",
    "    n_cols = min(3, n_images)\n",
    "    n_rows = (n_images + n_cols - 1) // n_cols\n",
    "    \n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(5 * n_cols, 5 * n_rows))\n",
    "    if n_images == 1:\n",
    "        axes = [axes]\n",
    "    else:\n",
    "        axes = axes.flatten()\n",
    "    \n",
    "    for i, (name, res) in enumerate(all_results):\n",
    "        ax = axes[i]\n",
    "        \n",
    "        # Convert BGR to RGB\n",
    "        img_rgb = cv2.cvtColor(res.image.copy(), cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # Draw boxes and keypoints\n",
    "        for face in res.faces:\n",
    "            box = face.bounding_box\n",
    "            cv2.rectangle(img_rgb, (box.x, box.y), \n",
    "                          (box.x + box.width, box.y + box.height), (255, 0, 0), 3)\n",
    "        \n",
    "        ax.imshow(img_rgb)\n",
    "        \n",
    "        # Overlay keypoints\n",
    "        for face in res.faces:\n",
    "            ax.scatter(face.keypoints[:, 0], face.keypoints[:, 1],\n",
    "                       c='cyan', s=30, marker='o', edgecolors='black', linewidths=0.5)\n",
    "        \n",
    "        ax.set_title(f\"{name}\\n({res.n_faces} face{'s' if res.n_faces != 1 else ''})\")\n",
    "        ax.axis('off')\n",
    "    \n",
    "    # Hide unused axes\n",
    "    for i in range(n_images, len(axes)):\n",
    "        axes[i].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-15",
   "metadata": {},
   "source": [
    "## 7. Using Individual Components\n",
    "\n",
    "You can also use `FaceDetector` and `KeypointPredictor` separately for more control."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use FaceDetector independently\n",
    "if cascade_path.exists() and image_files:\n",
    "    detector = FaceDetector(\n",
    "        cascade_path=str(cascade_path),\n",
    "        scale_factor=1.2,\n",
    "        min_neighbors=5,\n",
    "    )\n",
    "    \n",
    "    # Load first image\n",
    "    test_img = cv2.imread(str(image_files[0]))\n",
    "    \n",
    "    # Detect faces\n",
    "    boxes = detector.detect(test_img)\n",
    "    \n",
    "    print(f\"FaceDetector Results\")\n",
    "    print(\"=\" * 40)\n",
    "    print(f\"Image: {image_files[0].name}\")\n",
    "    print(f\"Detected {len(boxes)} face(s):\\n\")\n",
    "    \n",
    "    for i, box in enumerate(boxes):\n",
    "        print(f\"Face {i + 1}:\")\n",
    "        print(f\"  Position: ({box.x}, {box.y})\")\n",
    "        print(f\"  Size: {box.width} x {box.height}\")\n",
    "        print(f\"  Area: {box.area} pixels\")\n",
    "        print(f\"  Center: {box.center}\")\n",
    "    \n",
    "    # Visualize\n",
    "    fig = plot_face_detections(test_img, boxes, title=f\"Face Detection: {len(boxes)} face(s)\")\n",
    "    plt.show()\n",
    "else:\n",
    "    boxes = []\n",
    "    print(\"Cannot run detector - missing cascade file or images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use KeypointPredictor independently\n",
    "if use_model_path and boxes:\n",
    "    predictor = KeypointPredictor(\n",
    "        model_path=str(use_model_path),\n",
    "        image_size=96,\n",
    "    )\n",
    "    \n",
    "    # Get first face crop\n",
    "    box = boxes[0]\n",
    "    face_crop = detector.crop_face(test_img, box, padding=0.1)\n",
    "    \n",
    "    # Predict keypoints\n",
    "    prediction = predictor.predict(face_crop, denormalize=True)\n",
    "    \n",
    "    print(\"KeypointPredictor Results\")\n",
    "    print(\"=\" * 40)\n",
    "    print(f\"Raw output shape: {prediction.raw_output.shape}\")\n",
    "    print(f\"Keypoints shape: {prediction.keypoints.shape}\")\n",
    "    print(f\"\\nKeypoint coordinates (in 96x96 space):\")\n",
    "    \n",
    "    KEYPOINT_NAMES = [\n",
    "        'left_eye_center', 'right_eye_center', 'left_eye_inner', 'left_eye_outer',\n",
    "        'right_eye_inner', 'right_eye_outer', 'left_eyebrow_in', 'left_eyebrow_out',\n",
    "        'right_eyebrow_in', 'right_eyebrow_out', 'nose_tip',\n",
    "        'mouth_left', 'mouth_right', 'mouth_top', 'mouth_bottom'\n",
    "    ]\n",
    "    \n",
    "    for i, ((x, y), name) in enumerate(zip(prediction.keypoints, KEYPOINT_NAMES)):\n",
    "        print(f\"  {i:2d}. {name:20s}: ({x:6.2f}, {y:6.2f})\")\n",
    "    \n",
    "    # Visualize on the face crop\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
    "    \n",
    "    # Original crop\n",
    "    axes[0].imshow(cv2.cvtColor(face_crop, cv2.COLOR_BGR2RGB))\n",
    "    axes[0].set_title('Face Crop (original)')\n",
    "    axes[0].axis('off')\n",
    "    \n",
    "    # Resized with keypoints\n",
    "    gray_crop = cv2.cvtColor(face_crop, cv2.COLOR_BGR2GRAY)\n",
    "    gray_resized = cv2.resize(gray_crop, (96, 96))\n",
    "    plot_keypoints(gray_resized, prediction.keypoints.flatten(), ax=axes[1],\n",
    "                   marker_color='cyan', marker_size=60)\n",
    "    axes[1].set_title('Keypoints on 96x96 crop')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Cannot run predictor - missing model or no faces detected\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-18",
   "metadata": {},
   "source": [
    "## 8. Compare Detection Modes\n",
    "\n",
    "Compare `detect_all=True` (all faces) vs `detect_all=False` (largest face only)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find an image with multiple faces for comparison\n",
    "if pipeline and image_files:\n",
    "    # Try to find image with multiple faces, or use any available\n",
    "    multi_face_candidates = ['obamas.jpg', 'obamas_with_keypoints.png']\n",
    "    test_path = None\n",
    "    \n",
    "    for candidate in multi_face_candidates:\n",
    "        candidate_path = images_dir / candidate\n",
    "        if candidate_path.exists():\n",
    "            test_path = candidate_path\n",
    "            break\n",
    "    \n",
    "    if test_path is None and image_files:\n",
    "        test_path = image_files[0]\n",
    "    \n",
    "    if test_path:\n",
    "        print(f\"Testing detection modes on: {test_path.name}\")\n",
    "        \n",
    "        fig, axes = plt.subplots(1, 2, figsize=(16, 8))\n",
    "        \n",
    "        # Detect all faces\n",
    "        result_all = pipeline.process(str(test_path), detect_all=True)\n",
    "        img_all = cv2.cvtColor(result_all.image.copy(), cv2.COLOR_BGR2RGB)\n",
    "        for face in result_all.faces:\n",
    "            box = face.bounding_box\n",
    "            cv2.rectangle(img_all, (box.x, box.y),\n",
    "                          (box.x + box.width, box.y + box.height), (0, 255, 0), 3)\n",
    "        axes[0].imshow(img_all)\n",
    "        for face in result_all.faces:\n",
    "            axes[0].scatter(face.keypoints[:, 0], face.keypoints[:, 1],\n",
    "                            c='cyan', s=40, edgecolors='black', linewidths=0.5)\n",
    "        axes[0].set_title(f'detect_all=True ({result_all.n_faces} faces)')\n",
    "        axes[0].axis('off')\n",
    "        \n",
    "        # Detect single (largest) face\n",
    "        result_single = pipeline.process(str(test_path), detect_all=False)\n",
    "        img_single = cv2.cvtColor(result_single.image.copy(), cv2.COLOR_BGR2RGB)\n",
    "        for face in result_single.faces:\n",
    "            box = face.bounding_box\n",
    "            cv2.rectangle(img_single, (box.x, box.y),\n",
    "                          (box.x + box.width, box.y + box.height), (255, 0, 0), 3)\n",
    "        axes[1].imshow(img_single)\n",
    "        for face in result_single.faces:\n",
    "            axes[1].scatter(face.keypoints[:, 0], face.keypoints[:, 1],\n",
    "                            c='yellow', s=40, edgecolors='black', linewidths=0.5)\n",
    "        axes[1].set_title(f'detect_all=False (largest face)')\n",
    "        axes[1].axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "else:\n",
    "    print(\"Cannot run comparison - pipeline not initialized or no images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-20",
   "metadata": {},
   "source": [
    "## 9. Export Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_annotated_image(result, output_path, draw_boxes=True, draw_keypoints=True):\n",
    "    \"\"\"Save processed result to an image file with annotations.\"\"\"\n",
    "    img = result.image.copy()\n",
    "    \n",
    "    for face in result.faces:\n",
    "        box = face.bounding_box\n",
    "        \n",
    "        if draw_boxes:\n",
    "            cv2.rectangle(img, (box.x, box.y),\n",
    "                          (box.x + box.width, box.y + box.height), (0, 255, 0), 2)\n",
    "        \n",
    "        if draw_keypoints:\n",
    "            for x, y in face.keypoints:\n",
    "                cv2.circle(img, (int(x), int(y)), 3, (0, 255, 255), -1)\n",
    "    \n",
    "    cv2.imwrite(str(output_path), img)\n",
    "    print(f\"Saved: {output_path}\")\n",
    "\n",
    "def export_keypoints_json(result, output_path, image_name=\"\"):\n",
    "    \"\"\"Export keypoints to JSON format.\"\"\"\n",
    "    data = {\n",
    "        \"image\": image_name,\n",
    "        \"n_faces\": result.n_faces,\n",
    "        \"faces\": []\n",
    "    }\n",
    "    \n",
    "    for i, face in enumerate(result.faces):\n",
    "        face_data = {\n",
    "            \"face_id\": i,\n",
    "            \"bounding_box\": {\n",
    "                \"x\": int(face.bounding_box.x),\n",
    "                \"y\": int(face.bounding_box.y),\n",
    "                \"width\": int(face.bounding_box.width),\n",
    "                \"height\": int(face.bounding_box.height),\n",
    "            },\n",
    "            \"keypoints\": [\n",
    "                {\"x\": float(x), \"y\": float(y)}\n",
    "                for x, y in face.keypoints\n",
    "            ]\n",
    "        }\n",
    "        data[\"faces\"].append(face_data)\n",
    "    \n",
    "    with open(output_path, 'w') as f:\n",
    "        json.dump(data, f, indent=2)\n",
    "    \n",
    "    print(f\"Exported: {output_path}\")\n",
    "\n",
    "# Save results\n",
    "if result:\n",
    "    output_dir = PROJECT_ROOT / 'output'\n",
    "    output_dir.mkdir(exist_ok=True)\n",
    "    \n",
    "    save_annotated_image(result, output_dir / 'annotated_result.jpg')\n",
    "    export_keypoints_json(result, output_dir / 'keypoints.json', \n",
    "                          image_name=image_files[0].name if image_files else \"\")\n",
    "    \n",
    "    print(f\"\\nOutput saved to: {output_dir}\")\n",
    "else:\n",
    "    print(\"No results to export\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-22",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrated:\n",
    "\n",
    "1. **Pipeline Usage**: `FacialKeypointsPipeline` for end-to-end face detection + keypoint prediction\n",
    "2. **Visualization**: `plot_pipeline_result()` and related functions\n",
    "3. **Component Access**: Using `FaceDetector` and `KeypointPredictor` independently\n",
    "4. **Batch Processing**: Processing multiple images from a directory\n",
    "5. **Detection Modes**: Comparing all faces vs. single largest face\n",
    "6. **Export**: Saving results as annotated images or JSON\n",
    "\n",
    "### API Quick Reference\n",
    "\n",
    "```python\n",
    "# High-level pipeline\n",
    "from facial_keypoints.pipeline import FacialKeypointsPipeline\n",
    "\n",
    "pipeline = FacialKeypointsPipeline(cascade_path, model_path)\n",
    "result = pipeline.process(image)  # Returns PipelineResult\n",
    "\n",
    "# Result contains:\n",
    "result.n_faces        # Number of detected faces\n",
    "result.image          # Original image\n",
    "result.faces          # List of FaceKeypointsResult\n",
    "\n",
    "# Each face contains:\n",
    "face.bounding_box     # BoundingBox with x, y, width, height\n",
    "face.keypoints        # np.ndarray of shape (15, 2)\n",
    "\n",
    "# Low-level components\n",
    "from facial_keypoints.detection.face_detector import FaceDetector\n",
    "from facial_keypoints.models.predictor import KeypointPredictor\n",
    "\n",
    "detector = FaceDetector(cascade_path)\n",
    "boxes = detector.detect(image)  # Returns list[BoundingBox]\n",
    "\n",
    "predictor = KeypointPredictor(model_path)\n",
    "prediction = predictor.predict(face_crop)  # Returns KeypointPrediction\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
